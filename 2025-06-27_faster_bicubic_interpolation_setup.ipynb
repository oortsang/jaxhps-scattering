{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9f1899-33f9-4ced-87fa-0d455b7e508a",
   "metadata": {},
   "source": [
    "## Consider a building the bicubic interpolation operator faster?\n",
    "The current bicubic interpolation operator works well but is not vectorized and only runs on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72de9ece-5c6a-499e-9024-5c903d7b34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "from jaxhps.quadrature import (\n",
    "    barycentric_lagrange_interpolation_matrix_2D,\n",
    "    chebyshev_points,\n",
    ")\n",
    "\n",
    "from rlc_repo_link.src.data.data_transformations import (\n",
    "    prep_conv_interp_2d,\n",
    "    apply_interp_2d,\n",
    "    # Maybe I could leverage the separability to use the 1d operators?\n",
    "    prep_conv_interp_1d,\n",
    "    apply_interp_1d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5aea43-df77-471a-9de3-2b632d73b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_fn_handle = lambda x: q_gaussian_bumps(0.75 * x)\n",
    "bump_center = jnp.array([0.1, 0.0])\n",
    "# bump_center = jnp.array([0.0, 0.0])\n",
    "amplitude = 2\n",
    "sigma = 0.15\n",
    "q_fn_handle = lambda x: amplitude * jnp.exp(-0.5*jnp.sum( ((x-bump_center)/sigma)**2 ,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e566456-4eb2-46f8-9427-6746676ac1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=2, N=64\n"
     ]
    }
   ],
   "source": [
    "tree_n_per_leaf = 16\n",
    "tree_L = 2\n",
    "tree_p = 16\n",
    "tree_n = 2**tree_L * tree_n_per_leaf\n",
    "\n",
    "print(f\"L={tree_L}, N={tree_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3425f7ab-e113-4602-a0d0-0970b5b98b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_cheb_x = chebyshev_points(tree_p)\n",
    "leaf_cheb_y = chebyshev_points(tree_p)[::-1]\n",
    "leaf_to_tree = lambda xs: jnp.concatenate([\n",
    "    (xs+1) * (1/2**tree_L) - 1 + (2*i/2**tree_L)\n",
    "    for i in range(2**tree_L)\n",
    "])\n",
    "tree_cheb_x = leaf_to_tree(leaf_cheb_x)\n",
    "tree_cheb_y = leaf_to_tree(leaf_cheb_y)\n",
    "\n",
    "cell_offset = 0 # 0.5 for centered\n",
    "leaf_unif_x = (cell_offset/tree_n_per_leaf)+jnp.linspace(-1, 1, tree_n_per_leaf, endpoint=False)\n",
    "leaf_unif_y = (cell_offset/tree_n_per_leaf)+jnp.linspace(-1, 1, tree_n_per_leaf, endpoint=False) # [::-1]\n",
    "tree_unif_x = (cell_offset/tree_n)+jnp.linspace(-1, 1, tree_n, endpoint=False)\n",
    "tree_unif_y = (cell_offset/tree_n)+jnp.linspace(-1, 1, tree_n, endpoint=False)\n",
    "\n",
    "product_grid = lambda xs, ys: jnp.array(jnp.meshgrid(xs, ys, indexing=\"ij\")).transpose(1,2,0).reshape(-1,2)\n",
    "leaf_cheb_xy = product_grid(leaf_cheb_x, leaf_cheb_y)\n",
    "leaf_unif_xy = product_grid(leaf_unif_x, leaf_unif_y)\n",
    "tree_unif_xy = product_grid(tree_unif_x, tree_unif_y)\n",
    "tree_cheb_xy = product_grid(tree_cheb_x, tree_cheb_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4d653494-69c5-469f-b419-37cb5d833b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 3.9 s, total: 18.9 s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_unif_to_cheb_x, tree_unif_to_cheb_y = prep_conv_interp_2d(\n",
    "    tree_unif_x,\n",
    "    tree_unif_y,\n",
    "    tree_cheb_xy,\n",
    "    # use a zero-valued boundary condition to mimic empty neighboring leaves\n",
    "    bc_modes=(\"extend\", \"periodic\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "591a09d9-0240-450a-851b-ff0485d359ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_conv_interp_1d_faster(\n",
    "    points: np.ndarray,\n",
    "    xi: np.ndarray,\n",
    "    bc_mode: str = None,\n",
    "    a_neg_half: bool = True,\n",
    ") -> scipy.sparse.csr_array:\n",
    "    \"\"\"Alternate implementation written to use some vectorization\n",
    "    Prepares a sparse array to apply convolution for cubic interpolation\n",
    "    Operates in a single dimension and can be applied to each dimension independently\n",
    "    to work with higher-dimension data\n",
    "\n",
    "    Assumes that the entries in `points` are sorted and evenly spaced\n",
    "    Args:\n",
    "        points (ndarray): original data grid points\n",
    "        xi (ndarray): array of points to be sampled as a (m,)-shaped array\n",
    "        bc_mode (string): how to handle the boundary conditions\n",
    "            options:\n",
    "                \"periodic\": wrap values around\n",
    "                \"extend\": extrapolate the missing out-of-boundary values\n",
    "                    using a rule for cartesian points: f(-1) = 3*f(0) - 3*f(1) + f(2)\n",
    "                    (see R. Keys 1981 paper below)\n",
    "                \"zero\": sets values outside the boundary to zero\n",
    "        a_neg_half (bool): whether to use a=-1/2 for the convolution filter (otherwise use a=-3/4)\n",
    "    Returns:\n",
    "        conv_filter (m by n): sparse linear filter to perform\n",
    "            cubic interpolation (on padded data)\n",
    "            Apply to data values with `apply_interp_{1,2}d`\n",
    "            Note: padding should not be needed except for the inside edge of a polar grid\n",
    "\n",
    "    For the choice of convolution filter for cubic convolution\n",
    "    See https://en.wikipedia.org/wiki/Bicubic_interpolation#Bicubic_convolution_algorithm\n",
    "    and R. Keys (1981). \"Cubic convolution interpolation for digital image processing\".\n",
    "        IEEE Transactions on Acoustics, Speech, and Signal Processing.\n",
    "        29 (6): 1153â€“1160. Bibcode:1981ITASS..29.1153K. CiteSeerX 10.1.1.320.776.\n",
    "        doi:10.1109/TASSP.1981.1163711 .\n",
    "    \"\"\"\n",
    "    bc_mode = bc_mode.lower() if bc_mode is not None else \"zero\"\n",
    "    # Helper variables\n",
    "    periodic_mode = bc_mode == \"periodic\"\n",
    "    extend_mode = bc_mode == \"extend\"\n",
    "    zero_mode = bc_mode == \"zero\"\n",
    "\n",
    "    if a_neg_half:\n",
    "        # with a=-1/2, standard choice (seems to be the Catmull-Rom filter?)\n",
    "        cubic_conv_matrix = 0.5 * np.array(\n",
    "            [[0, 2, 0, 0], [-1, 0, 1, 0], [2, -5, 4, -1], [-1, 3, -3, 1]]\n",
    "        )\n",
    "    else:\n",
    "        # with a=-3/4, computed with sympy\n",
    "        # Sometimes gives lower error but has weaker theoretical properties...\n",
    "        cubic_conv_matrix = 0.25 * np.array(\n",
    "            [[0, 4, 0, 0], [-3, 0, 3, 0], [6, -9, 6, -3], [-3, 5, -5, 3]]\n",
    "        )\n",
    "\n",
    "    n = points.shape[0]\n",
    "    min_pt = points[0]\n",
    "    # interval between regularly sampled points\n",
    "    itvl = (points[-1] - points[0]) / ( n - 1 )\n",
    "    m = xi.shape[0]\n",
    "\n",
    "    # Faster to build in LIL form then convert later to CSR\n",
    "    interp_op = scipy.sparse.lil_array((m, n))\n",
    "\n",
    "    js_float, xs_offset = np.divmod(xi - min_pt, itvl)\n",
    "    js = js_float.astype(int)\n",
    "    # print(f\"js shape: {js.shape}; xs_offset shape: {xs_offset.shape}\")\n",
    "    pos_rel_vec = xs_offset / itvl\n",
    "    monomials_mat = np.stack(\n",
    "        [\n",
    "            np.ones(m),\n",
    "            pos_rel_vec,\n",
    "            pos_rel_vec**2,\n",
    "            pos_rel_vec**3\n",
    "        ], axis=1\n",
    "    )\n",
    "    filters_local = monomials_mat @ cubic_conv_matrix\n",
    "\n",
    "    # First handle the cases fully in bounds...\n",
    "    # Identify the target points that are fully in bounds...\n",
    "    tgt_idcs = np.arange(m)\n",
    "    tgt_pts_in_bounds  = np.logical_and(js>=1, js<=n-3) # boolean array\n",
    "    tgt_idcs_in_bounds = tgt_idcs[tgt_pts_in_bounds]    # index array (target points in bounds)\n",
    "    js_idcs_in_bounds  = js[tgt_pts_in_bounds]          # index array (~relevant source points)\n",
    "\n",
    "    # Just load the values one-by-one to avoid unholy indexing sorcery\n",
    "    filters_local_in_bounds = filters_local[tgt_pts_in_bounds]\n",
    "    interp_op[tgt_idcs_in_bounds, js_idcs_in_bounds-1] = filters_local_in_bounds[:, 0]\n",
    "    interp_op[tgt_idcs_in_bounds, js_idcs_in_bounds+0] = filters_local_in_bounds[:, 1]\n",
    "    interp_op[tgt_idcs_in_bounds, js_idcs_in_bounds+1] = filters_local_in_bounds[:, 2]\n",
    "    interp_op[tgt_idcs_in_bounds, js_idcs_in_bounds+2] = filters_local_in_bounds[:, 3]\n",
    "\n",
    "    # Handle the boundary conditions \n",
    "    tgt_pts_out_bounds  = np.logical_not(tgt_pts_in_bounds)\n",
    "    tgt_idcs_out_bounds = tgt_idcs[tgt_pts_out_bounds]\n",
    "    js_idcs_out_bounds  = js[tgt_pts_out_bounds]\n",
    "    if periodic_mode:\n",
    "        filters_local_out_bounds = filters_local[tgt_pts_out_bounds]\n",
    "        interp_op[tgt_idcs_out_bounds, (js_idcs_out_bounds-1)%n] = filters_local_out_bounds[:, 0]\n",
    "        interp_op[tgt_idcs_out_bounds, (js_idcs_out_bounds+0)%n] = filters_local_out_bounds[:, 1]\n",
    "        interp_op[tgt_idcs_out_bounds, (js_idcs_out_bounds+1)%n] = filters_local_out_bounds[:, 2]\n",
    "        interp_op[tgt_idcs_out_bounds, (js_idcs_out_bounds+2)%n] = filters_local_out_bounds[:, 3]\n",
    "    else:\n",
    "        for i in tgt_idcs_out_bounds:\n",
    "            x = xi[i]\n",
    "            j = js[i]\n",
    "            filter_local = filters_local[i]\n",
    "            # Assumes zero value beyond the extra single-cell padding\n",
    "            # Extrapolation rule was linear anyway so fold down the extrapolation\n",
    "            # into a reduced-length filter\n",
    "            if extend_mode:\n",
    "                if j < 1 and (j + 3) >= 0:\n",
    "                    filter_folded = filter_local[1:] + filter_local[0] * np.array(\n",
    "                        [3, -3, 1]\n",
    "                    )\n",
    "                    interp_op[i, : j + 3] = filter_folded[: j + 3]\n",
    "                elif j < n and (j + 3) >= n:\n",
    "                    filter_folded = filter_local[:-1] + filter_local[-1] * np.array(\n",
    "                        [1, -3, 3]\n",
    "                    )\n",
    "                    interp_op[i, j - 1 :] = filter_folded[: n - j + 1]\n",
    "            else:  # bc_mode == \"zero\" case\n",
    "                if j < 1 and (j + 3) >= 0:\n",
    "                    interp_op[i, : j + 3] = filter_local[: j + 3]\n",
    "                elif j < n and (j + 3) >= n:\n",
    "                    interp_op[i, j - 1 :] = filter_local[: n - j + 1]\n",
    "    # tgt_pts_out_bounds  = np.logical_not(tgt_pts_in_bounds)\n",
    "    # tgt_idcs_out_bounds = tgt_idcs[tgt_pts_out_bounds]\n",
    "    # for i in tgt_idcs_out_bounds:\n",
    "    #     x = xi[i]\n",
    "    #     j = js[i]\n",
    "    #     filter_local = filters_local[i]\n",
    "    #     if periodic_mode:\n",
    "    #         j_idcs = np.arange(j-1, j+3) % n\n",
    "    #         interp_op[i, j_idcs] = filter_local\n",
    "    #     elif extend_mode:\n",
    "    #         # Assumes zero value beyond the extra single-cell padding\n",
    "    #         # Extrapolation rule was linear anyway so fold down the extrapolation\n",
    "    #         # into a reduced-length filter\n",
    "    #         if j < 1 and (j + 3) >= 0:\n",
    "    #             filter_folded = filter_local[1:] + filter_local[0] * np.array(\n",
    "    #                 [3, -3, 1]\n",
    "    #             )\n",
    "    #             interp_op[i, : j + 3] = filter_folded[: j + 3]\n",
    "    #         elif j < n and (j + 3) >= n:\n",
    "    #             filter_folded = filter_local[:-1] + filter_local[-1] * np.array(\n",
    "    #                 [1, -3, 3]\n",
    "    #             )\n",
    "    #             interp_op[i, j - 1 :] = filter_folded[: n - j + 1]\n",
    "    #     else:  # bc_mode == \"zero\" case\n",
    "    #         if j < 1 and (j + 3) >= 0:\n",
    "    #             interp_op[i, : j + 3] = filter_local[: j + 3]\n",
    "    #         elif j < n and (j + 3) >= n:\n",
    "    #             interp_op[i, j - 1 :] = filter_local[: n - j + 1]\n",
    "\n",
    "    # Convert for slightly faster application\n",
    "    interp_op = scipy.sparse.csr_array(interp_op)\n",
    "    return interp_op\n",
    "        \n",
    "def prep_conv_interp_2d_faster(\n",
    "    points_x: np.ndarray,\n",
    "    points_y: np.ndarray,\n",
    "    xi: np.ndarray,\n",
    "    bc_modes: None | str | Tuple = None,\n",
    "    a_neg_half: bool = True,\n",
    ") -> Tuple[scipy.sparse.csr_array, scipy.sparse.csr_array]:\n",
    "    should_split = hasattr(bc_modes, \"__len__\") and len(bc_modes) == 2\n",
    "    bc_mode_x = bc_modes[0] if should_split else bc_modes\n",
    "    bc_mode_y = bc_modes[1] if should_split else bc_modes\n",
    "    interp_op_x = prep_conv_interp_1d_faster(\n",
    "        points_x, xi[:, 0], bc_mode=bc_mode_x, a_neg_half=a_neg_half\n",
    "    )\n",
    "    interp_op_y = prep_conv_interp_1d_faster(\n",
    "        points_y, xi[:, 1], bc_mode=bc_mode_y, a_neg_half=a_neg_half\n",
    "    )\n",
    "    return interp_op_x, interp_op_y\n",
    "\n",
    "# def apply_interp_1d(\n",
    "#     interp_op: scipy.sparse.csr_array, data_vals: np.ndarray\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"Applies the x/y convolutional filter operators onto the padded values\n",
    "#         ~ diag(conv_x (vals) conv_y^T)\n",
    "#     interp_op is   m x nx\n",
    "#     data_vals is nx x {1, ny}\n",
    "#     result is m (or m x ny) interpolated values\n",
    "#     \"\"\"\n",
    "#     res = interp_op @ data_vals  # .sum(1) # (m, ny+2) to (m,)\n",
    "#     return res\n",
    "\n",
    "\n",
    "# def apply_interp_2d(\n",
    "#     interp_op_x: scipy.sparse.csr_array,\n",
    "#     interp_op_y: scipy.sparse.csr_array,\n",
    "#     data_vals: np.ndarray,\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"Applies the x/y convolutional filters onto the padded values\n",
    "#         ~ diag(conv_x (vals) conv_y^T)\n",
    "#     Args:\n",
    "#         interp_op_x (sparse csr array): x-dim interpolation operator with shape (m, nx)\n",
    "#         interp_op_y (sparse csr array): y-dim interpolation operator with shape (m, ny)\n",
    "#         data_vals (ndarray): data values arranged in a grid (nx, ny)\n",
    "#     Returns:\n",
    "#         result (ndarray) is the interpolated values in a (m,) array\n",
    "#     \"\"\"\n",
    "#     post_x = interp_op_x @ data_vals  # m x (ny+2)\n",
    "#     res = (post_x * interp_op_y).sum(1)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0235e6a9-cd59-43d4-82f9-bc91ac66778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "js shape: (4096,); xs_offset shape: (4096,)\n",
      "monomials_mat shape: (4096, 4)\n",
      "filters_local shape: (4096, 4)\n",
      "js shape: (4096,); xs_offset shape: (4096,)\n",
      "monomials_mat shape: (4096, 4)\n",
      "filters_local shape: (4096, 4)\n",
      "CPU times: user 706 ms, sys: 95.3 ms, total: 801 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_unif_to_cheb_x_faster, tree_unif_to_cheb_y_faster = prep_conv_interp_2d_faster(\n",
    "    tree_unif_x,\n",
    "    tree_unif_y,\n",
    "    tree_cheb_xy,\n",
    "    # use a zero-valued boundary condition to mimic empty neighboring leaves\n",
    "    bc_modes=(\"extend\", \"periodic\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f63a216f-6d1f-4805-8100-df210cbe6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches? True\n",
      "Matches in x: True\n",
      "Matches in y: True\n"
     ]
    }
   ],
   "source": [
    "matches_in_x = np.allclose(tree_unif_to_cheb_x_faster.todense(), tree_unif_to_cheb_x.todense())\n",
    "matches_in_y = np.allclose(tree_unif_to_cheb_y_faster.todense(), tree_unif_to_cheb_y.todense())\n",
    "print(f\"Matches? {matches_in_x and matches_in_y}\")\n",
    "print(f\"Matches in x: {matches_in_x}\")\n",
    "print(f\"Matches in y: {matches_in_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c52ada-a6e2-49ae-a7e4-083624282856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f0541-8b20-4f85-b4ac-6301d265e3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e86c1e-dc40-4afb-ae23-24c787df4608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc1bd0-6933-410a-8ad6-27404c2c4aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxhps-env",
   "language": "python",
   "name": "jaxhps-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
